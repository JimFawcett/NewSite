<svg viewBox="0 0 1200 900" xmlns="http://www.w3.org/2000/svg">
  <!-- Define styles -->
  <defs>
    <style>
      .title { font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; fill: #2c3e50; }
      .subtitle { font-family: Arial, sans-serif; font-size: 16px; font-weight: bold; fill: #34495e; }
      .label { font-family: Arial, sans-serif; font-size: 14px; fill: #2c3e50; }
      .small-label { font-family: Arial, sans-serif; font-size: 11px; fill: #555; }
      .block-box { fill: #ecf0f1; stroke: #34495e; stroke-width: 3; }
      .attention-box { fill: #e74c3c; stroke: #c0392b; stroke-width: 2; }
      .ffn-box { fill: #2ecc71; stroke: #27ae60; stroke-width: 2; }
      .norm-box { fill: #f39c12; stroke: #d68910; stroke-width: 1.5; }
      .neuron { fill: #3498db; stroke: #2980b9; stroke-width: 1.5; }
      .connection { stroke: #95a5a6; stroke-width: 0.8; opacity: 0.4; }
      .arrow { fill: none; stroke: #34495e; stroke-width: 2; marker-end: url(#arrowhead); }
      .residual { fill: none; stroke: #e67e22; stroke-width: 2; stroke-dasharray: 5,5; }
    </style>
    <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" fill="#34495e" />
    </marker>
  </defs>
  
  <!-- Title -->
  <text x="600" y="35" class="title" text-anchor="middle">Modern Deep Learning: Stacked Transformer Blocks</text>
  <text x="600" y="60" class="subtitle" text-anchor="middle">Each "layer" contains multiple neural networks</text>
  
  <!-- Input -->
  <rect x="250" y="90" width="700" height="40" class="norm-box" rx="5"/>
  <text x="600" y="115" class="label" text-anchor="middle">Input Embeddings (Token + Positional)</text>
  
  <path d="M 600 130 L 600 155" class="arrow"/>
  
  <!-- Transformer Block 1 (Collapsed) -->
  <rect x="250" y="155" width="700" height="80" class="block-box" rx="5"/>
  <text x="600" y="185" class="subtitle" text-anchor="middle">Transformer Block 1</text>
  <text x="600" y="205" class="small-label" text-anchor="middle">Multi-Head Attention + Feed-Forward Network</text>
  <text x="600" y="220" class="small-label" text-anchor="middle" font-style="italic">(Collapsed - contains multiple neural networks inside)</text>
  
  <path d="M 600 235 L 600 260" class="arrow"/>
  
  <!-- Transformer Block 2 (Collapsed) -->
  <rect x="250" y="260" width="700" height="80" class="block-box" rx="5"/>
  <text x="600" y="290" class="subtitle" text-anchor="middle">Transformer Block 2</text>
  <text x="600" y="310" class="small-label" text-anchor="middle">Multi-Head Attention + Feed-Forward Network</text>
  <text x="600" y="325" class="small-label" text-anchor="middle" font-style="italic">(Collapsed - contains multiple neural networks inside)</text>
  
  <path d="M 600 340 L 600 365" class="arrow"/>
  
  <!-- Transformer Block 3 (EXPANDED) -->
  <rect x="250" y="365" width="700" height="380" class="block-box" rx="5"/>
  <text x="600" y="390" class="subtitle" text-anchor="middle">Transformer Block 3 (EXPANDED VIEW)</text>
  
  <!-- Layer Norm 1 -->
  <rect x="270" y="405" width="660" height="30" class="norm-box" rx="3"/>
  <text x="600" y="425" class="small-label" text-anchor="middle">Layer Normalization</text>
  
  <!-- Attention Box -->
  <rect x="270" y="445" width="660" height="80" class="attention-box" rx="3"/>
  <text x="600" y="465" class="label" text-anchor="middle" fill="white">Multi-Head Self-Attention</text>
  <text x="600" y="485" class="small-label" text-anchor="middle" fill="white">Q, K, V projections (each is a neural network)</text>
  <text x="600" y="505" class="small-label" text-anchor="middle" fill="white">8-64 parallel attention heads</text>
  
  <!-- Residual connection 1 -->
  <path d="M 245 420 Q 220 420 220 485 Q 220 550 245 550" class="residual"/>
  <text x="190" y="490" class="small-label" fill="#e67e22">Residual</text>
  
  <!-- Layer Norm 2 -->
  <rect x="270" y="535" width="660" height="30" class="norm-box" rx="3"/>
  <text x="600" y="555" class="small-label" text-anchor="middle">Layer Normalization</text>
  
  <!-- Feed-Forward Network (DETAILED) -->
  <rect x="270" y="575" width="660" height="150" class="ffn-box" rx="3"/>
  <text x="600" y="595" class="label" text-anchor="middle" fill="white">Feed-Forward Network (Neural Network)</text>
  
  <!-- Mini neural network inside FFN -->
  <g>
    <!-- Input layer (3 neurons) -->
    <circle cx="380" cy="630" r="8" class="neuron"/>
    <circle cx="380" cy="660" r="8" class="neuron"/>
    <circle cx="380" cy="690" r="8" class="neuron"/>
    
    <!-- Hidden layer 1 (5 neurons) -->
    <circle cx="480" cy="615" r="8" class="neuron"/>
    <circle cx="480" cy="645" r="8" class="neuron"/>
    <circle cx="480" cy="675" r="8" class="neuron"/>
    <circle cx="480" cy="705" r="8" class="neuron"/>
    
    <!-- Hidden layer 2 (5 neurons) -->
    <circle cx="580" cy="615" r="8" class="neuron"/>
    <circle cx="580" cy="645" r="8" class="neuron"/>
    <circle cx="580" cy="675" r="8" class="neuron"/>
    <circle cx="580" cy="705" r="8" class="neuron"/>
    
    <!-- Output layer (3 neurons) -->
    <circle cx="680" cy="630" r="8" class="neuron"/>
    <circle cx="680" cy="660" r="8" class="neuron"/>
    <circle cx="680" cy="690" r="8" class="neuron"/>
    
    <!-- Connections Input to Hidden 1 -->
    <line x1="388" y1="630" x2="472" y2="615" class="connection"/>
    <line x1="388" y1="630" x2="472" y2="645" class="connection"/>
    <line x1="388" y1="630" x2="472" y2="675" class="connection"/>
    <line x1="388" y1="630" x2="472" y2="705" class="connection"/>
    
    <line x1="388" y1="660" x2="472" y2="615" class="connection"/>
    <line x1="388" y1="660" x2="472" y2="645" class="connection"/>
    <line x1="388" y1="660" x2="472" y2="675" class="connection"/>
    <line x1="388" y1="660" x2="472" y2="705" class="connection"/>
    
    <line x1="388" y1="690" x2="472" y2="615" class="connection"/>
    <line x1="388" y1="690" x2="472" y2="645" class="connection"/>
    <line x1="388" y1="690" x2="472" y2="675" class="connection"/>
    <line x1="388" y1="690" x2="472" y2="705" class="connection"/>
    
    <!-- Connections Hidden 1 to Hidden 2 -->
    <line x1="488" y1="615" x2="572" y2="615" class="connection"/>
    <line x1="488" y1="615" x2="572" y2="645" class="connection"/>
    <line x1="488" y1="615" x2="572" y2="675" class="connection"/>
    <line x1="488" y1="615" x2="572" y2="705" class="connection"/>
    
    <line x1="488" y1="645" x2="572" y2="615" class="connection"/>
    <line x1="488" y1="645" x2="572" y2="645" class="connection"/>
    <line x1="488" y1="645" x2="572" y2="675" class="connection"/>
    <line x1="488" y1="645" x2="572" y2="705" class="connection"/>
    
    <line x1="488" y1="675" x2="572" y2="615" class="connection"/>
    <line x1="488" y1="675" x2="572" y2="645" class="connection"/>
    <line x1="488" y1="675" x2="572" y2="675" class="connection"/>
    <line x1="488" y1="675" x2="572" y2="705" class="connection"/>
    
    <line x1="488" y1="705" x2="572" y2="615" class="connection"/>
    <line x1="488" y1="705" x2="572" y2="645" class="connection"/>
    <line x1="488" y1="705" x2="572" y2="675" class="connection"/>
    <line x1="488" y1="705" x2="572" y2="705" class="connection"/>
    
    <!-- Connections Hidden 2 to Output -->
    <line x1="588" y1="615" x2="672" y2="630" class="connection"/>
    <line x1="588" y1="615" x2="672" y2="660" class="connection"/>
    <line x1="588" y1="615" x2="672" y2="690" class="connection"/>
    
    <line x1="588" y1="645" x2="672" y2="630" class="connection"/>
    <line x1="588" y1="645" x2="672" y2="660" class="connection"/>
    <line x1="588" y1="645" x2="672" y2="690" class="connection"/>
    
    <line x1="588" y1="675" x2="672" y2="630" class="connection"/>
    <line x1="588" y1="675" x2="672" y2="660" class="connection"/>
    <line x1="588" y1="675" x2="672" y2="690" class="connection"/>
    
    <line x1="588" y1="705" x2="672" y2="630" class="connection"/>
    <line x1="588" y1="705" x2="672" y2="660" class="connection"/>
    <line x1="588" y1="705" x2="672" y2="690" class="connection"/>
    
    <!-- Labels -->
    <text x="380" y="615" class="small-label" text-anchor="middle">Input</text>
    <text x="480" y="600" class="small-label" text-anchor="middle">Hidden 1</text>
    <text x="580" y="600" class="small-label" text-anchor="middle">Hidden 2</text>
    <text x="680" y="615" class="small-label" text-anchor="middle">Output</text>
  </g>
  
  <text x="600" y="610" class="small-label" text-anchor="middle" fill="white">Typical: d_model → 4×d_model → d_model</text>
  <text x="600" y="715" class="small-label" text-anchor="middle" fill="white">Example: 4096 → 16,384 → 4096 dimensions</text>
  
  <!-- Residual connection 2 -->
  <path d="M 245 550 Q 220 550 220 660 Q 220 730 245 730" class="residual"/>
  <text x="190" y="665" class="small-label" fill="#e67e22">Residual</text>
  
  <!-- Layer Norm 3 -->
  <rect x="270" y="730" width="660" height="30" class="norm-box" rx="3"/>
  <text x="600" y="750" class="small-label" text-anchor="middle">Layer Normalization (Output of Block 3)</text>
  
  <path d="M 600 745 L 600 775" class="arrow"/>
  
  <!-- Transformer Block 4 (Collapsed) -->
  <rect x="250" y="775" width="700" height="80" class="block-box" rx="5"/>
  <text x="600" y="805" class="subtitle" text-anchor="middle">Transformer Block 4</text>
  <text x="600" y="825" class="small-label" text-anchor="middle">Multi-Head Attention + Feed-Forward Network</text>
  <text x="600" y="840" class="small-label" text-anchor="middle" font-style="italic">(Collapsed - contains multiple neural networks inside)</text>
  
  <!-- Continuation indicator -->
  <text x="600" y="875" class="label" text-anchor="middle" font-weight="bold">⋮</text>
  <text x="600" y="895" class="small-label" text-anchor="middle" font-style="italic">Continues for 12-120+ blocks total</text>
  
  <!-- Legend/Explanation Box -->
  <rect x="20" y="150" width="210" height="280" class="block-box" rx="5" fill="#f8f9fa"/>
  <text x="125" y="175" class="subtitle" text-anchor="middle">Key Insight</text>
  
  <text x="30" y="200" class="small-label" font-weight="bold">Traditional DNN:</text>
  <text x="30" y="218" class="small-label">• Stack simple neuron layers</text>
  <text x="30" y="233" class="small-label">• Each layer: just neurons</text>
  
  <text x="30" y="263" class="small-label" font-weight="bold">Modern LLMs:</text>
  <text x="30" y="281" class="small-label">• Stack complex blocks</text>
  <text x="30" y="296" class="small-label">• Each block contains:</text>
  <text x="40" y="311" class="small-label">  - Attention (neural nets)</text>
  <text x="40" y="326" class="small-label">  - FFN (neural nets)</text>
  <text x="40" y="341" class="small-label">  - Normalizations</text>
  <text x="40" y="356" class="small-label">  - Residual connections</text>
  
  <text x="30" y="386" class="small-label" font-weight="bold">One block ≈ multiple</text>
  <text x="30" y="401" class="small-label" font-weight="bold">traditional DNN layers!</text>
  
  <text x="30" y="420" class="small-label" font-style="italic">Block 3 shows the</text>
  <text x="30" y="435" class="small-label" font-style="italic">internal structure →</text>
  
  <!-- Stats Box -->
  <rect x="970" y="150" width="210" height="200" class="block-box" rx="5" fill="#f8f9fa"/>
  <text x="1075" y="175" class="subtitle" text-anchor="middle">Scale Examples</text>
  
  <text x="980" y="200" class="small-label" font-weight="bold">GPT-3:</text>
  <text x="980" y="215" class="small-label">• 96 transformer blocks</text>
  <text x="980" y="230" class="small-label">• Each with ~1.8B params</text>
  <text x="980" y="245" class="small-label">• Total: 175B parameters</text>
  
  <text x="980" y="270" class="small-label" font-weight="bold">Llama 3 (70B):</text>
  <text x="980" y="285" class="small-label">• 80 transformer blocks</text>
  <text x="980" y="300" class="small-label">• 8,192 hidden dims</text>
  
  <text x="980" y="325" class="small-label" font-weight="bold">Claude 3:</text>
  <text x="980" y="340" class="small-label">• Architecture undisclosed</text>
</svg>